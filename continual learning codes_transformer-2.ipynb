{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBjuQVYD/hmjYqI8nLQsey"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gho9HZDiaPcD","executionInfo":{"status":"ok","timestamp":1758131861035,"user_tz":420,"elapsed":329028,"user":{"displayName":"Hossein Taheri","userId":"10565663845480396106"}},"outputId":"9ab70bb8-cb60-446f-c0e2-7c05179cbd30"},"outputs":[{"output_type":"stream","name":"stdout","text":["expm: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["expm: 1\n","expm: 2\n","expm: 3\n","expm: 4\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random, numpy as np\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","\n","# -------------------\n","# Parameters\n","# -------------------\n","d = 60         # input dimension\n","N = 10         # context size\n","K = 2          # number of tasks\n","noise_std = 1/(d**0.5)\n","epochs = 120   # gradient steps per task\n","lr = .01      # learning rate\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","\n","\n","class HingeLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, preds, labels):\n","        return torch.mean(F.relu(1 - preds * labels))\n","# -------------------\n","# Data generation\n","# -------------------\n","def generate_task_data(N, m, d, noise_std, w):\n","    X_full, y_tasks = [], []\n","    for _ in range(m):\n","        y_task = torch.randint(0, 2, (1,), device=device) * 2 - 1\n","        y_tasks.append(y_task.item())\n","        X_ctx = y_task * w + noise_std * torch.randn(N, d, device=device)\n","        X_full.append(X_ctx)\n","    X_full = torch.stack(X_full)\n","    y_tasks = torch.tensor(y_tasks, device=device)\n","    return X_full, y_tasks\n","\n","# -------------------\n","# Attention Layer\n","\n","\n","class SimpleTransformer(nn.Module):\n","    def __init__(self, input_dim, num_heads=1, num_layers=1, hidden_dim=30):\n","        super().__init__()\n","\n","        # 1. Define a single, standard transformer encoder layer.\n","        #    batch_first=True is crucial for using (Batch, Sequence, Feature) input shape.\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=input_dim,\n","            nhead=num_heads,\n","            dim_feedforward=hidden_dim * 2, # A common choice for the internal MLP dimension\n","            activation='relu',\n","            batch_first=True\n","        )\n","\n","        # 2. Stack the encoder layers into a single nn.TransformerEncoder module.\n","        self.transformer_encoder = nn.TransformerEncoder(\n","            encoder_layer=encoder_layer,\n","            num_layers=num_layers\n","        )\n","\n","        # 3. Define the final MLP head for the classification/regression task.\n","        #    This remains the same as your original implementation.\n","        self.mlp_head = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: (batch_size, seq_len=N, d_model=input_dim)\n","        \"\"\"\n","        # Pass the input through the transformer encoder stack.\n","        # The output has the same shape as the input.\n","        out = self.transformer_encoder(x)\n","\n","        # Average the output features across the sequence length dimension.\n","        out = out.mean(dim=1)\n","\n","        # Pass the result through the final MLP head.\n","        return self.mlp_head(out).squeeze(-1)\n","\n","# Example Usage:\n","# model = SimpleTransformerBuiltIn(input_dim=128, num_heads=4, num_layers=2, hidden_dim=300)\n","# input_tensor = torch.randn(32, 50, 128) # (Batch Size, Sequence Length, Input Dim)\n","# output = model(input_tensor)\n","# print(output.shape) # Expected: torch.Size([32])\n","\n","# -------------------\n","# One experiment\n","# -------------------\n","def run_experiment(seed):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","    model = SimpleTransformer(input_dim=d).to(device)\n","    optimizer = optim.SGD(model.parameters(), lr=lr)\n","    logistic_loss = HingeLoss()\n","\n","    per_task_losses = [[] for _ in range(K)]\n","    first_task_losses = []\n","\n","    # Generate tasks\n","    tasks_data = []\n","    for l in range(K):\n","        if l >= 1:\n","            w = torch.zeros(d, device=device)\n","            w[l] = 1/(2*d)**0.5\n","            m = 1000\n","        else:\n","            w = torch.zeros(d, device=device)\n","            w[0] = 1/(2*d)**0.5\n","            m = 50\n","        X_full, y_query = generate_task_data(N, m, d, noise_std, w)\n","        tasks_data.append((X_full, y_query))\n","\n","    X_first, y_first = tasks_data[0]\n","\n","    # Train sequentially\n","    for task_id in range(K):\n","        X_full, y_query = tasks_data[task_id]\n","        for epoch in range(epochs):\n","            optimizer.zero_grad()\n","            logits = model(X_full)\n","            loss = logistic_loss(logits, y_query)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Record losses\n","            with torch.no_grad():\n","                logits_first = model(X_first)\n","                loss_first = logistic_loss(logits_first, y_first)\n","                first_task_losses.append(loss_first.item())\n","\n","                logits_current = model(X_full)\n","                loss_current = logistic_loss(logits_current, y_query)\n","                per_task_losses[task_id].append(loss_current.item())\n","\n","    return first_task_losses, per_task_losses,logits_current\n","\n","# -------------------\n","# Run 10 experiments\n","# -------------------\n","n_experiments = 10\n","all_first_losses = []\n","all_per_task_losses = []\n","\n","for exp in range(n_experiments):\n","    print(\"expm:\",exp)\n","    first_losses, per_task_losses,logits_current = run_experiment(seed=exp)\n","    all_first_losses.append(first_losses)\n","    all_per_task_losses.append(per_task_losses)\n","\n","# Average across experiments\n","avg_first_losses = np.mean(np.array(all_first_losses), axis=0)\n","avg_per_task_losses = [np.mean(np.array([exp_losses[t] for exp_losses in all_per_task_losses]), axis=0)\n","                       for t in range(K)]\n","\n","#print(\"Average first task loss (last epoch):\", avg_first_losses[-1])\n","#for t in range(K):\n"," #   print(f\"Average final loss for task {t+1}:\", avg_per_task_losses[t][-1])\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import random, numpy as np\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","\n","# -------------------\n","# Parameters\n","# -------------------\n","d = 60         # input dimension\n","N = 10         # context size\n","K = 2          # number of tasks\n","noise_std = 1/(d**0.5)\n","epochs = 120   # gradient steps per task\n","lr = .01      # learning rate\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# -------------------\n","# Logistic Loss\n","# -------------------\n","class logloss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","    def forward(self, preds, labels):\n","        return torch.mean(torch.log(1+torch.exp(-preds*labels)))\n","class HingeLoss(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, preds, labels):\n","        return torch.mean(F.relu(1 - preds * labels))\n","# -------------------\n","# Data generation\n","# -------------------\n","def generate_task_data(N, m, d, noise_std, w):\n","    X_full, y_tasks = [], []\n","    for _ in range(m):\n","        y_task = torch.randint(0, 2, (1,), device=device) * 2 - 1\n","        y_tasks.append(y_task.item())\n","        X_ctx = y_task * w + noise_std * torch.randn(N, d, device=device)\n","        X_full.append(X_ctx)\n","    X_full = torch.stack(X_full)\n","    y_tasks = torch.tensor(y_tasks, device=device)\n","    return X_full, y_tasks\n","\n","# -------------------\n","# Attention Layer\n","\n","\n","class SimpleTransformer(nn.Module):\n","    def __init__(self, input_dim, num_heads=1, num_layers=1, hidden_dim=10):\n","        super().__init__()\n","\n","        # 1. Define a single, standard transformer encoder layer.\n","        #    batch_first=True is crucial for using (Batch, Sequence, Feature) input shape.\n","        encoder_layer = nn.TransformerEncoderLayer(\n","            d_model=input_dim,\n","            nhead=num_heads,\n","            dim_feedforward=hidden_dim, # A common choice for the internal MLP dimension\n","            activation='relu',\n","            batch_first=True\n","        )\n","\n","        # 2. Stack the encoder layers into a single nn.TransformerEncoder module.\n","        self.transformer_encoder = nn.TransformerEncoder(\n","            encoder_layer=encoder_layer,\n","            num_layers=num_layers\n","        )\n","\n","        # 3. Define the final MLP head for the classification/regression task.\n","        #    This remains the same as your original implementation.\n","        self.mlp_head = nn.Sequential(\n","            nn.Linear(input_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","\n","    def forward(self, x):\n","        \"\"\"\n","        x: (batch_size, seq_len=N, d_model=input_dim)\n","        \"\"\"\n","        # Pass the input through the transformer encoder stack.\n","        # The output has the same shape as the input.\n","        out = self.transformer_encoder(x)\n","\n","        # Average the output features across the sequence length dimension.\n","        out = out.mean(dim=1)\n","\n","        # Pass the result through the final MLP head.\n","        return self.mlp_head(out).squeeze(-1)\n","\n","# Example Usage:\n","# model = SimpleTransformerBuiltIn(input_dim=128, num_heads=4, num_layers=2, hidden_dim=300)\n","# input_tensor = torch.randn(32, 50, 128) # (Batch Size, Sequence Length, Input Dim)\n","# output = model(input_tensor)\n","# print(output.shape) # Expected: torch.Size([32])\n","\n","# -------------------\n","# One experiment\n","# -------------------\n","def run_experiment(seed,samplesize):\n","    torch.manual_seed(seed)\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","    model = SimpleTransformer(input_dim=d).to(device)\n","    optimizer = optim.SGD(model.parameters(), lr=lr)\n","    logistic_loss = HingeLoss()\n","\n","    per_task_losses = [[] for _ in range(K)]\n","    first_task_losses = []\n","\n","    # Generate tasks\n","    tasks_data = []\n","    for l in range(K):\n","        if l >= 1:\n","            w = torch.zeros(d, device=device)\n","            w[l] = 1/(2*d)**0.5\n","            m = samplesize\n","        else:\n","            w = torch.zeros(d, device=device)\n","            w[0] = 1/(2*d)**0.5\n","            m = 50\n","        X_full, y_query = generate_task_data(N, m, d, noise_std, w)\n","        tasks_data.append((X_full, y_query))\n","\n","    X_first, y_first = tasks_data[0]\n","\n","    # Train sequentially\n","    for task_id in range(K):\n","        X_full, y_query = tasks_data[task_id]\n","        for epoch in range(epochs):\n","            optimizer.zero_grad()\n","            logits = model(X_full)\n","            loss = logistic_loss(logits, y_query)\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Record losses\n","            with torch.no_grad():\n","                logits_first = model(X_first)\n","                loss_first = logistic_loss(logits_first, y_first)\n","                first_task_losses.append(loss_first.item())\n","\n","                logits_current = model(X_full)\n","                loss_current = logistic_loss(logits_current, y_query)\n","                per_task_losses[task_id].append(loss_current.item())\n","\n","    return first_task_losses, per_task_losses,logits_current\n","\n","# -------------------\n","# Run 10 experiments\n","# -------------------\n","n_experiments = 10\n","avg_first_losses=[]\n","avg_per_task_losses =[]\n","for mm in [20,50,200,500,1000,2000]:\n","    all_first_losses = []\n","    all_per_task_losses = []\n","    for exp in range(n_experiments):\n","        print(\"expm:\",exp)\n","        print(\"m:\",mm)\n","\n","        first_losses, per_task_losses,logits_current = run_experiment(seed=exp,samplesize=mm)\n","        all_first_losses.append(first_losses)\n","        all_per_task_losses.append(per_task_losses)\n","\n","    # Average across experiments\n","    avg_first_losses.append(np.mean(np.array(all_first_losses), axis=0))\n","    avg_per_task_losses.append([np.mean(np.array([exp_losses[t] for exp_losses in all_per_task_losses]), axis=0)\n","                          for t in range(K)])\n","\n","#print(\"Average first task loss (last epoch):\", avg_first_losses[-1])\n","#for t in range(K):\n"," #   print(f\"Average final loss for task {t+1}:\", avg_per_task_losses[t][-1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WflH5mHO1M7W","executionInfo":{"status":"ok","timestamp":1758133348209,"user_tz":420,"elapsed":740475,"user":{"displayName":"Hossein Taheri","userId":"10565663845480396106"}},"outputId":"15ea6e96-4072-4d62-e455-9761ed014301"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["expm: 0\n","m: 20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["expm: 1\n","m: 20\n","expm: 2\n","m: 20\n","expm: 3\n","m: 20\n","expm: 4\n","m: 20\n","expm: 5\n","m: 20\n","expm: 6\n","m: 20\n","expm: 7\n","m: 20\n","expm: 8\n","m: 20\n","expm: 9\n","m: 20\n","expm: 0\n","m: 50\n","expm: 1\n","m: 50\n","expm: 2\n","m: 50\n","expm: 3\n","m: 50\n","expm: 4\n","m: 50\n","expm: 5\n","m: 50\n","expm: 6\n","m: 50\n","expm: 7\n","m: 50\n","expm: 8\n","m: 50\n","expm: 9\n","m: 50\n","expm: 0\n","m: 200\n","expm: 1\n","m: 200\n","expm: 2\n","m: 200\n","expm: 3\n","m: 200\n","expm: 4\n","m: 200\n","expm: 5\n","m: 200\n","expm: 6\n","m: 200\n","expm: 7\n","m: 200\n","expm: 8\n","m: 200\n","expm: 9\n","m: 200\n","expm: 0\n","m: 500\n","expm: 1\n","m: 500\n","expm: 2\n","m: 500\n","expm: 3\n","m: 500\n","expm: 4\n","m: 500\n","expm: 5\n","m: 500\n","expm: 6\n","m: 500\n","expm: 7\n","m: 500\n","expm: 8\n","m: 500\n","expm: 9\n","m: 500\n","expm: 0\n","m: 1000\n","expm: 1\n","m: 1000\n","expm: 2\n","m: 1000\n","expm: 3\n","m: 1000\n","expm: 4\n","m: 1000\n","expm: 5\n","m: 1000\n","expm: 6\n","m: 1000\n","expm: 7\n","m: 1000\n","expm: 8\n","m: 1000\n","expm: 9\n","m: 1000\n","expm: 0\n","m: 2000\n","expm: 1\n","m: 2000\n","expm: 2\n","m: 2000\n","expm: 3\n","m: 2000\n","expm: 4\n","m: 2000\n","expm: 5\n","m: 2000\n","expm: 6\n","m: 2000\n","expm: 7\n","m: 2000\n","expm: 8\n","m: 2000\n","expm: 9\n","m: 2000\n"]}]}]}